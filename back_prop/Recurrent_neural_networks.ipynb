{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "This homework assignment is largely inspired from [this tutoriel on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/).\n",
    "We probably need to polish the text.\n",
    "\n",
    "They key exercise is coding the backpropagation. A gradient check function is given to have feedback about the correctness of the implementation, without giving the answer.\n",
    "The level can be adapted by guiding more or less inside the function.\n",
    "Other functions could also be given as exercise (e.g. `forward_propagation` and `train_with_sgd`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation in Recurrent Neural Networks\n",
    "\n",
    "In this notebook, we implement a RNN from scratch using numpy arrays.\n",
    "\n",
    "The biggest part is already implemented, but you will have to write the backpropagation function.\n",
    "\n",
    "\n",
    "### What are RNNs?\n",
    "\n",
    "The idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that’s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations. Another way to think about RNNs is that they have a “memory” which captures information about what has been calculated so far. In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps. Here is what a typical RNN looks like:\n",
    "\n",
    "\n",
    "![](http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg)\n",
    "\n",
    "\n",
    "The above diagram shows a RNN being unrolled (or unfolded) into a full network. By unrolling we simply mean that we write out the network for the complete sequence. For example, if the sequence we care about is a sentence of 5 words, the network would be unrolled into a 5-layer neural network, one layer for each word. The formulas that govern the computation happening in a RNN are as follows:\n",
    "\n",
    "\\begin{aligned}\n",
    "s_t &= f(Ux_t + Ws_{t-1}) \\\\\n",
    "o_t &= \\mathrm{softmax}(Vs_t)\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "- $x_t$ is the input at time step $t$. For example, $x_1$ could be a one-hot vector corresponding to the second word of a sentence.\n",
    "- $s_t$ is the hidden state at time step $t$. It’s the “memory” of the network. $s_t$ is calculated based on the previous hidden state and the input at the current step. The function $f$ usually is a nonlinearity such as tanh or ReLU.  $s_{-1}$, which is required to calculate the first hidden state, is typically initialized to all zeroes.\n",
    "- $o_t$ is the output at step $t$. For example, if we wanted to predict the next word in a sentence it would be a vector of probabilities across our vocabulary.\n",
    "\n",
    "There are a few things to note here:\n",
    "\n",
    "You can think of the hidden state $s_t$ as the memory of the network. $s_t$ captures information about what happened in all the previous time steps. The output at step $o_t$ is calculated solely based on the memory at time $t$. As briefly mentioned above, it’s a bit more complicated  in practice because $s_t$ typically can’t capture information from too many time steps ago.\n",
    "Unlike a traditional deep neural network, which uses different parameters at each layer, a RNN shares the same parameters ($U$, $V$, $W$ above) across all steps. This reflects the fact that we are performing the same task at each step, just with different inputs. This greatly reduces the total number of parameters we need to learn.\n",
    "The above diagram has outputs at each time step, but depending on the task this may not be necessary. For example, when predicting the sentiment of a sentence we may only care about the final output, not the sentiment after each word. Similarly, we may not need inputs at each time step. The main feature of an RNN is its hidden state, which captures some information about a sequence.\n",
    "What can RNNs do?\n",
    "\n",
    "RNNs have shown great success in many NLP tasks. At this point I should mention that the most commonly used type of RNNs are LSTMs, which are much better at capturing long-term dependencies than vanilla RNNs are. But don’t worry, LSTMs are essentially the same thing as the RNN we will develop in this tutorial, they just have a different way of computing the hidden state. We’ll cover LSTMs in more detail in a later post. Here are some example applications of RNNs in NLP (by non means an exhaustive list).\n",
    "\n",
    "\n",
    "### Defining a toy problem\n",
    "\n",
    "Let's try to teach a RNN model how to add numbers. We will represent integers with a list of digits.\n",
    "\n",
    "Example: 142857 = [0 0 0 0 1 4 2 8 5 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "np.set_printoptions(precision=6, linewidth=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 2 8 5 7]\n",
      "142857\n"
     ]
    }
   ],
   "source": [
    "# utils\n",
    "n_digits = 7\n",
    "\n",
    "def softmax(x):\n",
    "    xt = np.exp(x - np.max(x))\n",
    "    return xt / np.sum(xt)\n",
    "\n",
    "def array_to_decimal(array):\n",
    "    return int(''.join([str(i) for i in array]), 10)\n",
    "\n",
    "def decimal_to_array(num, n_digits):\n",
    "    return np.int_(list((\"%%0%dd\" % n_digits) % num)[-n_digits:])\n",
    "\n",
    "print(decimal_to_array(142857, n_digits))\n",
    "print(array_to_decimal(decimal_to_array(142857, n_digits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              [9 4 0 1 9 0 1]\n",
      "            + [8 9 0 8 6 4 3]\n",
      "-----------------------------\n",
      "[0 0 0 0 0 0 1 8 3 1 0 5 4 4]\n"
     ]
    }
   ],
   "source": [
    "# Building a training set\n",
    "\n",
    "np.random.seed(10)\n",
    "n_samples = 1000\n",
    "\n",
    "X_train = np.random.randint(10, size=(n_samples, 2 * n_digits))\n",
    "y_train = np.zeros((n_samples, 2 * n_digits), dtype=int)\n",
    "for i in range(n_samples):\n",
    "    a = array_to_decimal(X_train[i, :n_digits])\n",
    "    b = array_to_decimal(X_train[i, n_digits:])\n",
    "    y_train[i] = decimal_to_array(a + b, 2 * n_digits)\n",
    "\n",
    "print('             ', X_train[0, :n_digits])\n",
    "print('            +', X_train[0, n_digits:])\n",
    "print('-----------------------------')\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input $x$ will be a sequence of digits (just like the example printed above) and each $x_t$ is a single digit, one-hot encoded into a vector in $\\mathbb{R}^{10}$.\n",
    "\n",
    "Let's recap the equations for the RNN:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "s_t &= \\tanh(Ux_t + Ws_{t-1}) \\\\\n",
    "o_t &= \\mathrm{softmax}(Vs_t)\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "I always find it useful to write down the dimensions of the matrices and vectors. We one-encoded the digits into $C=10$ classes, and let's assume we pick a hidden layer size $H = 100$. You can think of the hidden layer size as the \"memory\" of our network. Making it bigger allows us to learn more complex patterns, but also results in additional computation. Then we have:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "x_t & \\in \\mathbb{R}^{10} \\\\\n",
    "o_t & \\in \\mathbb{R}^{10} \\\\\n",
    "s_t & \\in \\mathbb{R}^{100} \\\\\n",
    "U & \\in \\mathbb{R}^{100 \\times 10} \\\\\n",
    "V & \\in \\mathbb{R}^{10 \\times 100} \\\\\n",
    "W & \\in \\mathbb{R}^{100 \\times 100} \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "This is valuable information. Remember that $U,V$ and $W$ are the parameters of our network we want to learn from data. Thus, we need to learn a total of $2HC + H^2$ parameters. The dimensions also tell us the bottleneck of our model. Note that because $x_t$ is a one-hot vector, multiplying it with $U$ is essentially the same as selecting a column of U, so we don't need to perform the full multiplication. Then, the biggest matrix multiplication in our network is $Vs_t$.\n",
    "\n",
    "Armed with this, it's time to start our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization\n",
    "\n",
    "We start by declaring a RNN class and initializing our parameters. We can't just initialize them to 0's because that would result in symmetric calculations in all our layers. We must initialize them randomly. Because proper initialization seems to have an impact on training results there has been lot of research in this area. It turns out that the best initialization depends on the activation function ($\\tanh$ in our case) and one [recommended](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf) approach is to initialize the weights randomly in the interval from $\\left[-\\frac{1}{\\sqrt{n}}, \\frac{1}{\\sqrt{n}}\\right]$ where $n$ is the number of incoming connections from the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_dim=10, hidden_dim=100, bptt_truncate=20):\n",
    "        # Assign instance variables\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bptt_truncate = bptt_truncate\n",
    "        # Randomly initialize the network parameters\n",
    "        self.U = np.random.uniform(-np.sqrt(1./input_dim), np.sqrt(1./input_dim), (hidden_dim, input_dim))\n",
    "        self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (input_dim, hidden_dim))\n",
    "        self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, `input_dim` is the size of each input, and `hidden_dim` is the size of our hidden layer (we can pick it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propagation\n",
    "\n",
    "Next, let's implement the forward propagation (predicting digit probabilities) defined by our equations above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(self, x):\n",
    "    # The total number of time steps\n",
    "    T = len(x)\n",
    "    # During forward propagation we save all hidden states in s because we need them later.\n",
    "    # We add one additional element for the initial hidden, which we set to 0\n",
    "    s = np.zeros((T + 1, self.hidden_dim))\n",
    "    s[-1] = np.zeros(self.hidden_dim)\n",
    "    # The outputs at each time step. Again, we save them for later.\n",
    "    o = np.zeros((T, self.input_dim))\n",
    "\n",
    "    # For each time step...\n",
    "    for t in np.arange(T):\n",
    "        # Note that we are indexing U by x[t]. This is the same as multiplying U with a one-hot vector.\n",
    "        s[t] = np.tanh(self.U[:,x[t]] + self.W.dot(s[t-1]))\n",
    "        o[t] = softmax(self.V.dot(s[t]))\n",
    "    return [o, s]\n",
    "\n",
    "RNN.forward_propagation = forward_propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We not only return the calculated outputs, but also the hidden states. We will use them later to calculate the gradients, and by returning them here we avoid duplicate computation. Each $o_t$ is a vector of probabilities representing the digits, but sometimes, for example when evaluating our model, all we want is the next digit with the highest probability. We call this function `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(self, x):\n",
    "    # Perform forward propagation and return index of the highest score\n",
    "    o, s = self.forward_propagation(x)\n",
    "    return np.argmax(o, axis=1)\n",
    "\n",
    "RNN.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our newly implemented methods and see an example output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 10)\n",
      "[[ 0.128147  0.086456  0.097282  0.102131  0.081564  0.108697  0.09797   0.106346  0.092526  0.098881]\n",
      " [ 0.095863  0.110619  0.112997  0.090618  0.094954  0.11318   0.086146  0.090954  0.110195  0.094474]\n",
      " [ 0.09886   0.101381  0.096624  0.077477  0.083638  0.100096  0.102021  0.11491   0.1099    0.115094]\n",
      " [ 0.098815  0.099052  0.106088  0.078864  0.078886  0.132081  0.107208  0.09466   0.100423  0.103924]\n",
      " [ 0.128161  0.098779  0.09455   0.103251  0.073019  0.122561  0.083596  0.113788  0.095242  0.087053]\n",
      " [ 0.090704  0.099418  0.10445   0.087798  0.092747  0.104899  0.099478  0.104261  0.111476  0.104769]\n",
      " [ 0.100745  0.099929  0.103282  0.079946  0.078899  0.127029  0.109987  0.093854  0.097476  0.108852]\n",
      " [ 0.106561  0.099488  0.090668  0.104637  0.100736  0.105507  0.08942   0.118487  0.106474  0.078023]\n",
      " [ 0.125611  0.08225   0.101721  0.105134  0.076596  0.112481  0.091433  0.104065  0.101788  0.098921]\n",
      " [ 0.094124  0.108361  0.106366  0.088721  0.092884  0.096963  0.098377  0.103662  0.105676  0.104866]\n",
      " [ 0.099961  0.083536  0.090912  0.103437  0.104206  0.106783  0.108902  0.111544  0.102765  0.087954]\n",
      " [ 0.106493  0.08944   0.110259  0.113656  0.085737  0.078956  0.096196  0.103045  0.104889  0.111327]\n",
      " [ 0.08962   0.103113  0.111665  0.081396  0.095164  0.112999  0.095312  0.097297  0.108801  0.104633]\n",
      " [ 0.091239  0.094241  0.10329   0.089598  0.093887  0.110267  0.116977  0.094623  0.101239  0.104638]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "model = RNN()\n",
    "o, s = model.forward_propagation(X_train[0])\n",
    "print(o.shape)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each digits in the sentence, our model made `n_digits` predictions representing probabilities of each digit. Note that because we initialized $U,V,W$ to random values these predictions are completely random right now. The following gives the indices of the highest probability predictions for each bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "[0 5 9 5 0 8 5 7 0 1 7 3 5 6]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train[0])\n",
    "print(predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Loss\n",
    "\n",
    "To train our network we need a way to measure the errors it makes. We call this the loss function $L$, and our goal is find the parameters $U,V$ and $W$ that minimize the loss function for our training data. A common choice for the loss function is the [cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression). If we have $N$ training examples (words in our text) and $C$ classes then the loss with respect to our predictions $o$ and the true labels $y$ is given by:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "L(y,o) = - \\frac{1}{N} \\sum_{n \\in N} y_{n} \\log o_{n}\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "The formula sums over our training examples and adds to the loss based on how off our prediction are. The further away $y$ (the correct words) and $o$ (our predictions), the greater the loss will be. We implement the function `calculate_loss`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_total_loss(self, x, y):\n",
    "    L = 0\n",
    "    # For each sentence...\n",
    "    for i in np.arange(len(y)):\n",
    "        o, s = self.forward_propagation(x[i])\n",
    "        # We only care about our prediction of the \"correct\" words\n",
    "        correct_word_predictions = o[np.arange(len(y[i])), y[i]]\n",
    "        # Add to the loss based on how off we were\n",
    "        L += -1 * np.sum(np.log(correct_word_predictions))\n",
    "    return L\n",
    "\n",
    "def calculate_loss(self, x, y):\n",
    "    # Divide the total loss by the number of training examples\n",
    "    N = np.sum((len(y_i) for y_i in y))\n",
    "    return self.calculate_total_loss(x,y)/N\n",
    "\n",
    "RNN.calculate_total_loss = calculate_total_loss\n",
    "RNN.calculate_loss = calculate_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the RNN with SGD and Backpropagation Through Time (BPTT)\n",
    "\n",
    "Remember that we want to find the parameters $U,V$ and $W$ that minimize the total loss on the training data. The most common way to do this is SGD, Stochastic Gradient Descent. The idea behind SGD is pretty simple. We iterate over all our training examples and during each iteration we nudge the parameters into a direction that reduces the error. These directions are given by the gradients on the loss: $\\frac{\\partial L}{\\partial U}, \\frac{\\partial L}{\\partial V}, \\frac{\\partial L}{\\partial W}$. SGD also needs a *learning rate*, which defines how big of a step we want to make in each iteration.\n",
    "\n",
    "But how do we calculate those gradients we mentioned above? In a traditional Neural Network we do this through the backpropagation algorithm. In RNNs we use a slightly modified version of the this algorithm called **Backpropagation Through Time (BPTT)**. Because the parameters are shared by all time steps in the network, the gradient at each output depends not only on the calculations of the current time step, but also the previous time steps. If you know calculus, it really is just applying the chain rule.\n",
    "\n",
    "Let's recall the RNN model:\n",
    "\n",
    "\\begin{aligned}  s_t &= \\tanh (U x_t + W s_{t-1})\\\\\n",
    "\\hat{y}_t &= \\text{softmax}(V s_t)\\end{aligned}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain rule\n",
    "\n",
    "To calculate these gradients we use the chain rule of differentiation. That’s the backpropagation algorithm when applied backwards starting from the error. For the rest we’ll use $E_3$ as an example, just to have concrete numbers to work with.\n",
    "\n",
    "\\begin{aligned}  \\frac{\\partial E_3}{\\partial V} &=\\frac{\\partial E_3}{\\partial \\hat{y}_3}\\frac{\\partial\\hat{y}_3}{\\partial V}\\\\  &=\\frac{\\partial E_3}{\\partial \\hat{y}_3}\\frac{\\partial\\hat{y}_3}{\\partial z_3}\\frac{\\partial z_3}{\\partial V}\\\\  &=(\\hat{y}_3 - y_3) \\otimes s_3 \\\\  \\end{aligned}  \n",
    "\n",
    "In the above, $z_3 =Vs_3$, and $\\otimes$  is the outer product of two vectors. You can try calculating these derivatives yourself (good exercise!). The point is that $\\frac{\\partial E_3}{\\partial V}$  only depends on the values at the current time step, $\\hat{y}_3, y_3, s_3$ . If you have these, calculating the gradient for $V$ a simple matrix multiplication.\n",
    "\n",
    "But the story is different for $\\frac{\\partial E_3}{\\partial W}$ (and for $U$). To see why, we write out the chain rule, just as above:\n",
    "\n",
    "\\begin{aligned}  \\frac{\\partial E_3}{\\partial W} &= \\frac{\\partial E_3}{\\partial \\hat{y}_3}\\frac{\\partial\\hat{y}_3}{\\partial s_3}\\frac{\\partial s_3}{\\partial W}\\\\  \\end{aligned}  \n",
    "\n",
    "Now, note that $s_3 = \\tanh(Ux_t + Ws_2)$ depends on $s_2$, which depends on $W$ and $s_1$, and so on. So if we take the derivative with respect to $W$ we can’t simply treat $s_2$ as a constant! We need to apply the chain rule again and what we really have is this:\n",
    "\n",
    "\\begin{aligned}  \\frac{\\partial E_3}{\\partial W} &= \\sum\\limits_{k=0}^{3} \\frac{\\partial E_3}{\\partial \\hat{y}_3}\\frac{\\partial\\hat{y}_3}{\\partial s_3}\\frac{\\partial s_3}{\\partial s_k}\\frac{\\partial s_k}{\\partial W}\\\\  \\end{aligned}  \n",
    "\n",
    "We sum up the contributions of each time step to the gradient. In other words, because $W$ is used in every step up to the output we care about, we need to backpropagate gradients from $t=3$ through the network all the way to $t=0$:\n",
    "\n",
    "![Image of Yaktocat](http://www.wildml.com/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png)\n",
    "\n",
    "Note that this is exactly the same as the standard backpropagation algorithm that we use in deep Feedforward Neural Networks. The key difference is that we sum up the gradients for W at each time step. In a traditional NN we don’t share parameters across layers, so we don’t need to sum anything. BPTT is just a fancy name for standard backpropagation on an unrolled RNN. Just like with Backpropagation you could define a delta vector that you pass backwards, e.g.: $\\delta_2^{(3)} = \\frac{\\partial E_3}{\\partial z_2} =\\frac{\\partial E_3}{\\partial s_3}\\frac{\\partial s_3}{\\partial s_2}\\frac{\\partial s_2}{\\partial z_2}$ with $z_2 = Ux_2+ Ws_1$. Then the same equations will apply.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Fill the function below to implement the Backpropagation Through Time (BPTT) algorithm.\n",
    "\n",
    "To check if your function is correct, you can use the `gradient_check` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bptt(self, x, y):\n",
    "    T = len(y)\n",
    "    # Perform forward propagation\n",
    "    o, s = self.forward_propagation(x)\n",
    "    # We accumulate the gradients in these variables\n",
    "    dLdU = np.zeros(self.U.shape)\n",
    "    dLdV = np.zeros(self.V.shape)\n",
    "    dLdW = np.zeros(self.W.shape)\n",
    "    delta_o = o\n",
    "    delta_o[np.arange(len(y)), y] -= 1.\n",
    "    # For each output backwards...\n",
    "    for t in np.arange(T)[::-1]:\n",
    "        # update dLdV\n",
    "        # ...\n",
    "\n",
    "        # Initial delta calculation\n",
    "        # ...\n",
    "\n",
    "        # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "        for bptt_step in np.arange(max(0, t-self.bptt_truncate), t+1)[::-1]:\n",
    "            # update dLdW\n",
    "            # ...\n",
    "\n",
    "            # update dLdU\n",
    "            # ...\n",
    "    \n",
    "            # Update delta for next step\n",
    "            # ...\n",
    "\n",
    "            pass\n",
    "    \n",
    "    return [dLdU, dLdV, dLdW]\n",
    "\n",
    "RNN.bptt = bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ((answer))\n",
    "\n",
    "def bptt(self, x, y):\n",
    "    T = len(y)\n",
    "    # Perform forward propagation\n",
    "    o, s = self.forward_propagation(x)\n",
    "    # We accumulate the gradients in these variables\n",
    "    dLdU = np.zeros(self.U.shape)\n",
    "    dLdV = np.zeros(self.V.shape)\n",
    "    dLdW = np.zeros(self.W.shape)\n",
    "    delta_o = o\n",
    "    delta_o[np.arange(len(y)), y] -= 1.\n",
    "    # For each output backwards...\n",
    "    for t in np.arange(T)[::-1]:\n",
    "        dLdV += np.outer(delta_o[t], s[t].T)\n",
    "        # Initial delta calculation\n",
    "        delta_t = self.V.T.dot(delta_o[t]) * (1 - (s[t] ** 2))\n",
    "        # Backpropagation through time (for at most self.bptt_truncate steps)\n",
    "        for bptt_step in np.arange(max(0, t-self.bptt_truncate), t+1)[::-1]:\n",
    "            dLdW += np.outer(delta_t, s[bptt_step-1])              \n",
    "            dLdU[:,x[bptt_step]] += delta_t\n",
    "            # Update delta for next step\n",
    "            delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n",
    "    return [dLdU, dLdV, dLdW]\n",
    "\n",
    "RNN.bptt = bptt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Checking\n",
    "\n",
    "Whenever you implement backpropagation it is good idea to also implement *gradient checking*, which is a way of verifying that your implementation is correct. The idea behind gradient checking is that derivative of a parameter is equal to the slope at the point, which we can approximate by slightly changing the parameter and then dividing by the change:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial \\theta} \\approx \\lim_{h \\to 0} \\frac{J(\\theta + h) - J(\\theta -h)}{2h}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "We then compare the gradient we calculated using backpropagation to the gradient we estimated with the method above. If there's no large difference we are good. The approximation needs to calculate the total loss for *every* parameter, so that gradient checking is very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing gradient check for parameter U with size 1000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cal/homes/tdupre/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check for parameter U passed.\n",
      "Performing gradient check for parameter V with size 1000.\n",
      "Gradient check for parameter V passed.\n",
      "Performing gradient check for parameter W with size 10000.\n",
      "Gradient check for parameter W passed.\n"
     ]
    }
   ],
   "source": [
    "def gradient_check(self, x, y, h=0.001, error_threshold=0.01):\n",
    "    # Calculate the gradients using backpropagation. We want to checker if these are correct.\n",
    "    bptt_gradients = model.bptt(x, y)\n",
    "    # List of all parameters we want to check.\n",
    "    model_parameters = ['U', 'V', 'W']\n",
    "    # Gradient check for each parameter\n",
    "    for pidx, pname in enumerate(model_parameters):\n",
    "        # Get the actual parameter value from the mode, e.g. model.W\n",
    "        parameter = operator.attrgetter(pname)(self)\n",
    "        print(\"Performing gradient check for parameter %s with size %d.\" % (pname, np.prod(parameter.shape)))\n",
    "        # Iterate over each element of the parameter matrix, e.g. (0,0), (0,1), ...\n",
    "        it = np.nditer(parameter, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        while not it.finished:\n",
    "            ix = it.multi_index\n",
    "            # Save the original value so we can reset it later\n",
    "            original_value = parameter[ix]\n",
    "            # Estimate the gradient using (f(x+h) - f(x-h))/(2*h)\n",
    "            parameter[ix] = original_value + h\n",
    "            gradplus = model.calculate_total_loss([x],[y])\n",
    "            parameter[ix] = original_value - h\n",
    "            gradminus = model.calculate_total_loss([x],[y])\n",
    "            estimated_gradient = (gradplus - gradminus)/(2*h)\n",
    "            # Reset parameter to original value\n",
    "            parameter[ix] = original_value\n",
    "            # The gradient for this parameter calculated using backpropagation\n",
    "            backprop_gradient = bptt_gradients[pidx][ix]\n",
    "            # calculate The relative error: (|x - y|/(|x| + |y|))\n",
    "            relative_error = np.abs(backprop_gradient - estimated_gradient)/(np.abs(backprop_gradient) + np.abs(estimated_gradient))\n",
    "            # If the error is to large fail the gradient check\n",
    "            if relative_error > error_threshold:\n",
    "                print(\"Gradient Check ERROR: parameter=%s ix=%s\" % (pname, ix))\n",
    "                print(\"+h Loss: %f\" % gradplus)\n",
    "                print(\"-h Loss: %f\" % gradminus)\n",
    "                print(\"Estimated_gradient: %f\" % estimated_gradient)\n",
    "                print(\"Backpropagation gradient: %f\" % backprop_gradient)\n",
    "                print(\"Relative Error: %f\" % relative_error)\n",
    "                return \n",
    "            it.iternext()\n",
    "        print(\"Gradient check for parameter %s passed.\" % (pname))\n",
    "\n",
    "RNN.gradient_check = gradient_check\n",
    "\n",
    "np.random.seed(10)\n",
    "model = RNN(10, 100, bptt_truncate=1000)\n",
    "model.gradient_check(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Implementation\n",
    "\n",
    "Now that we are able to calculate the gradients for our parameters we can implement SGD. I like to do this in two steps: 1. A function `sdg_step` that calculates the gradients and performs the updates for one batch. 2. An outer loop that iterates through the training set and adjusts the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performs one step of SGD.\n",
    "def sdg_step(self, x, y, learning_rate):\n",
    "    # Calculate the gradients\n",
    "    dLdU, dLdV, dLdW = self.bptt(x, y)\n",
    "    # Change parameters according to gradients and learning rate\n",
    "    self.U -= learning_rate * dLdU\n",
    "    self.V -= learning_rate * dLdV\n",
    "    self.W -= learning_rate * dLdW\n",
    "\n",
    "RNN.sgd_step = sdg_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_sgd(model, X_train, y_train, learning_rate=0.005, nepoch=100, evaluate_loss_after=5):\n",
    "    \"\"\"Outer SGD Loop\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - model: The RNN model instance\n",
    "    - X_train: The training data set\n",
    "    - y_train: The training data labels\n",
    "    - learning_rate: Initial learning rate for SGD\n",
    "    - nepoch: Number of times to iterate through the complete dataset\n",
    "    - evaluate_loss_after: Evaluate the loss after this many epochs\n",
    "    \"\"\"\n",
    "    # We keep track of the losses so we can plot them later\n",
    "    losses = []\n",
    "    num_examples_seen = 0\n",
    "    for epoch in range(nepoch):\n",
    "        # Optionally evaluate the loss\n",
    "        if (epoch % evaluate_loss_after == 0):\n",
    "            loss = model.calculate_loss(X_train, y_train)\n",
    "            losses.append((num_examples_seen, loss))\n",
    "            time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            print(\"%s: Loss after num_examples_seen=%d epoch=%d: %f\" % (time, num_examples_seen, epoch, loss))\n",
    "            # Adjust the learning rate if loss increases\n",
    "            if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n",
    "                learning_rate = learning_rate * 0.5  \n",
    "                print(\"Setting learning rate to %f\" % learning_rate)\n",
    "            sys.stdout.flush()\n",
    "        # For each training example...\n",
    "        for i in range(len(y_train)):\n",
    "            # One SGD step\n",
    "            model.sgd_step(X_train[i], y_train[i], learning_rate)\n",
    "            num_examples_seen += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-04 18:05:10: Loss after num_examples_seen=0 epoch=0: 2.302904\n",
      "2018-06-04 18:05:12: Loss after num_examples_seen=100 epoch=1: 1.509416\n",
      "2018-06-04 18:05:14: Loss after num_examples_seen=200 epoch=2: 1.375010\n",
      "2018-06-04 18:05:16: Loss after num_examples_seen=300 epoch=3: 1.335181\n",
      "2018-06-04 18:05:17: Loss after num_examples_seen=400 epoch=4: 1.294507\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "# Train on a small subset of the data to see what happens\n",
    "model = RNN()\n",
    "losses = train_with_sgd(model, X_train[:100], y_train[:100], nepoch=5, evaluate_loss_after=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, it seems like our implementation is at least doing something useful and decreasing the loss, just like we wanted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
